{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85fb75ca-15a0-4236-b316-50eaee2381de",
   "metadata": {},
   "source": [
    "# LM Evaluation Harness\n",
    "\n",
    "検証は rinna 3.6B を g5.2xlarge にて行った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47db66b-1caf-4bbf-af61-6ec379b2dd20",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876eb68-4947-4fac-84f4-3984bb0babd0",
   "metadata": {},
   "source": [
    "## Model の用意 (Optional)\n",
    "\n",
    "学習済みのモデルをローカルにダウンロードする。\n",
    "\n",
    "モデルは事前学習済みモデル、ファインチューニング/LoRA（Continuous Pretraining / Instruction Tuning）などを使用できます。\n",
    "\n",
    "[PMC-Llama](https://arxiv.org/abs/2304.14454) などでは対象のタスクでの Fine-tuning も行っています。必要に応じてタスクでの学習も行い性能を比較することも考えられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fcd90-b5bf-48e8-903d-f18f5b93185a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# アーティファクトのダウンロード\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "def get_latest_training_job_artifact(base_job_name):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    response = sagemaker_client.list_training_jobs(NameContains=base_job_name, SortBy='CreationTime', SortOrder='Descending')\n",
    "    training_job_arn = response['TrainingJobSummaries'][0]['TrainingJobArn']\n",
    "    training_job_description = sagemaker_client.describe_training_job(TrainingJobName=training_job_arn.split('/')[-1])\n",
    "    return training_job_description['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "# Job 名 でアーティファクトの S3 URL を取得\n",
    "model_data = get_latest_training_job_artifact('Rinna')\n",
    "\n",
    "!aws s3 cp {model_data} model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f10447-b47d-44c8-a6d2-690db44f32b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイルの解凍\n",
    "\n",
    "# LoRA の場合は True、Full Model の場合は False\n",
    "lora = False\n",
    "model_dir = \"downloaded_model\"\n",
    "\n",
    "# フォルダのクリーンアップ\n",
    "!rm -rf {model_dir} && mkdir {model_dir}\n",
    "\n",
    "# LoRA の場合は adapter_* など\n",
    "if lora:\n",
    "    !tar -xvf model.tar.gz -C {model_dir} --no-same-owner --wildcards adapter_*\n",
    "\n",
    "# Full Model の場合は pytorch_model* など\n",
    "else:\n",
    "    !tar -xvf model.tar.gz -C {model_dir} --no-same-owner --exclude checkpoint*\n",
    "\n",
    "    # SageMaker Model Parallel などのコードで実行した際の Artifact は fullmodel.pt なので HuggingFace 形式に変換\n",
    "    !mv {model_dir}/fullmodel.pt {model_dir}/pytorch_model.bin\n",
    "    import torch\n",
    "    user_content = torch.load(f\"{model_dir}/user_content_fullmodel.pt\")\n",
    "    hf_config = user_content['model_config']\n",
    "    hf_config.to_json_file(f\"{model_dir}/config.json\")\n",
    "\n",
    "    # トークナイザが保存されていない場合はトークナイザを保存する\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"rinna/japanese-gpt-neox-3.6b-instruction-ppo\",\n",
    "    )\n",
    "    tokenizer.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af7846-a3ee-466d-8ed9-eb234b866110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## カスタムデータセットの用意 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd564ce-fda8-4fa2-a315-fdb2582885b9",
   "metadata": {},
   "source": [
    "要約のサンプルとして `lm_eval/tasks/ja/xlsum_ja.py` を `lm_eval/tasks/ja/custom_summary.py` にコピーしていくつか書き換えたものがあります。\n",
    "また、`lm-evaluation-harness/lm_eval/tasks/__init__.py` もそれに合わせて編集しました。\n",
    "\n",
    "xlsum は Rogue2 を使用した評価を行います。\n",
    "\n",
    "このデータセットは `text`, `summary` のフィールドのデータセットを受け取り要約します。（例：https://huggingface.co/datasets/mkshing/xlsum_ja ）\n",
    "\n",
    "`lm_eval/tasks/ja/custom_summary.py` の `DATASET_PATH` を必要に応じて書き換えてください。（ローカルのパスもしくは Huggingface のデータセット ID）\n",
    "\n",
    "例として Wikihow データセットの変換を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9213a4a-706d-402a-aac8-82caadfaae42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p downloaded_dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"~/sagemaker_nlp_examples/Summarization/T5_training/test.csv\") # Wikihow データセットが保存されているパス\n",
    "df.rename(columns={'src': 'text', 'tgt': 'summary'}, inplace=True)\n",
    "df = df[:100]\n",
    "df.to_csv(\"downloaded_dataset/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0d422-c4f9-4310-898f-3e79a56be51f",
   "metadata": {},
   "source": [
    "## 評価の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38790d-6545-4eaa-af15-8d73aaf564e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -e \".[ja]\"\n",
    "!pip install \"accelerate>=0.20.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64984bb3-b6f2-4733-a4b1-6c0b2fdfb41d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c01349-9211-4ff0-a8fa-819dfeec6310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model_directory = \"models/rinna/rinna-japanese-gpt-neox-3.6b-customft\"\n",
    "custom_model_harness = f\"{custom_model_directory}/harness.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80905154-9079-4b80-88e7-60778246a3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {custom_model_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd8062-c611-4615-ab98-319c80d46e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile {custom_model_harness}\n",
    "# MODEL_ARGS=\"pretrained=downloaded_model,use_fast=False,device_map=auto,torch_dtype=auto,batch_size=4\"\n",
    "# TASK=\"jcommonsenseqa-1.1-0.4,jnli-1.1-0.4,marc_ja-1.1-0.4,jsquad-1.1-0.4,jaqket_v2-0.2-0.4,xlsum_ja-1.0-0.4,xwinograd_ja,mgsm-1.0-0.4,custom-1.0-0.0\"\n",
    "# python main.py --model hf-causal --model_args $MODEL_ARGS --tasks $TASK --num_fewshot \"3,3,3,2,1,1,0,5,0\" --device \"cuda\" --output_path \"models/rinna/rinna-japanese-gpt-neox-3.6b-customft/result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b49ccc-0a71-4126-bd7a-23ada51618af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {custom_model_harness}\n",
    "MODEL_ARGS=\"pretrained=downloaded_model,use_fast=False,device_map=auto,torch_dtype=auto,batch_size=4\"\n",
    "TASK=\"custom-1.0-0.0\"\n",
    "python main.py --model hf-causal --model_args $MODEL_ARGS --tasks $TASK --num_fewshot \"0\" --device \"cuda\" --output_path \"models/rinna/rinna-japanese-gpt-neox-3.6b-customft/result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3055a712-30ac-4167-a577-caedd58a4066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod u+x {custom_model_harness}\n",
    "!{custom_model_harness}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1bb20-2855-4317-a5d6-ef8b8f702781",
   "metadata": {},
   "source": [
    "### LoRA\n",
    "\n",
    "Full Model との差異として PEFT を読み込む実装がある `hf-causal-experimental` を使用している。\n",
    "\n",
    "LoRA をマージして Full Model として実行することも可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434db09-89a6-4012-ae63-7a29618a7b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model_directory = \"models/rinna/rinna-japanese-gpt-neox-3.6b-lora\"\n",
    "custom_model_harness = f\"{custom_model_directory}/harness.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d15d1-b195-4f0e-af3c-a77a6ce5cb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {custom_model_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066d4f7-4e03-4f15-b99f-302974fdf17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {custom_model_harness}\n",
    "MODEL_ARGS=\"pretrained=rinna/japanese-gpt-neox-3.6b,peft=downloaded_model,use_fast=False,device_map_option=auto,dtype=auto,batch_size=4\"\n",
    "TASK=\"custom-1.0-0.0\"\n",
    "python main.py --model hf-causal-experimental --model_args $MODEL_ARGS --tasks $TASK --num_fewshot \"0\" --device \"cuda\" --output_path \"models/rinna/rinna-japanese-gpt-neox-3.6b-lora/result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4acc2f-05fe-4bbd-8bd6-4d91550a3e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod u+x {custom_model_harness}\n",
    "!{custom_model_harness}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880d47a-c688-4730-ab86-c7da392147aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
